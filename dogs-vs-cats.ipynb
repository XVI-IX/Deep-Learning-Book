{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-14 09:21:31.913870: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-09-14 09:21:31.913972: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import os, shutil\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Conv2D, Flatten\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Directories for Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 17] File exists: '/home/xviix/Desktop/Learning/image-data': Base Directory Exists\n"
     ]
    }
   ],
   "source": [
    "# location of original data\n",
    "original_train_data = \"/home/xviix/Desktop/Learning/dogs-vs-cats/train\"\n",
    "original_test_data = \"/home/xviix/Desktop/Learning/dogs-vs-cats/test\"\n",
    "\n",
    "\n",
    "# directory to save new data\n",
    "base_directory = \"/home/xviix/Desktop/Learning/image-data\"\n",
    "try:\n",
    "  os.mkdir(base_directory)\n",
    "except FileExistsError as e:\n",
    "  print(f\"{e}: Base Directory Exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files Exists\n"
     ]
    }
   ],
   "source": [
    "train_dir = os.path.join(base_directory, \"train\")\n",
    "\n",
    "test_dir = os.path.join(base_directory, \"test\")\n",
    "\n",
    "val_dir = os.path.join(base_directory, \"validation\")\n",
    "\n",
    "try:\n",
    "  os.mkdir(train_dir)\n",
    "  os.mkdir(test_dir)\n",
    "  os.mkdir(val_dir)\n",
    "except FileExistsError as e:\n",
    "  print('Files Exists')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Creating Training, Testing and Validation Sets for cats**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cats_dir = os.path.join(train_dir, \"cats\")\n",
    "# test_cats_dir = os.path.join(test_dir, \"cats\")\n",
    "val_cats_dir = os.path.join(val_dir, \"cats\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Creating Training, Testing and Validation Sets for dogs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 17] File exists: '/home/xviix/Desktop/Learning/image-data/train/cats'\n"
     ]
    }
   ],
   "source": [
    "train_dogs_dir = os.path.join(train_dir, \"dogs\")\n",
    "# test_dogs_dir = os.path.join(test_dir, \"dogs\")\n",
    "val_dogs_dir = os.path.join(val_dir, \"dogs\")\n",
    "\n",
    "try:\n",
    "  os.mkdir(train_cats_dir)\n",
    "  os.mkdir(val_cats_dir)\n",
    "  os.mkdir(train_dogs_dir)\n",
    "  os.mkdir(val_dogs_dir)\n",
    "except Exception as e:\n",
    "  print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_names = [f\"cat.{i}.jpg\" for i in range(7000)]\n",
    "for file_name in file_names:\n",
    "  src = os.path.join(original_train_data, file_name)\n",
    "  dest = os.path.join(train_cats_dir, file_name)\n",
    "  shutil.copy(src, dest)\n",
    "\n",
    "# validation set for cats\n",
    "file_names = [f\"cat.{i}.jpg\" for i in range(7000, 12500)]\n",
    "for file_name in file_names:\n",
    "  src = os.path.join(original_train_data, file_name)\n",
    "  dest = os.path.join(val_cats_dir, file_name)\n",
    "  shutil.copy(src, dest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_names = [f\"dog.{i}.jpg\" for i in range(7000)]\n",
    "for file_name in file_names:\n",
    "  src = os.path.join(original_train_data, file_name)\n",
    "  dest = os.path.join(train_dogs_dir, file_name)\n",
    "  shutil.copy(src, dest)\n",
    "\n",
    "# validation set for dogs\n",
    "file_names = [f\"dog.{i}.jpg\" for i in range(7000, 12500)]\n",
    "for file_name in file_names:\n",
    "  src = os.path.join(original_train_data, file_name)\n",
    "  dest = os.path.join(val_dogs_dir, file_name)\n",
    "  shutil.copy(src, dest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test set for cats\n",
    "# file_names = [f\"cat.{i}.jpg\" for i in range(6250)]\n",
    "for file_name in os.listdir(original_test_data):\n",
    "  src = os.path.join(original_test_data, file_name)\n",
    "  dest = os.path.join(test_dir, file_name)\n",
    "  shutil.copy(src, dest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Instantiation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-14 09:23:03.576190: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-09-14 09:23:03.576226: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-09-14 09:23:03.576247: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (xviix): /proc/driver/nvidia/version does not exist\n",
      "2022-09-14 09:23:03.626275: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "  Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)),\n",
    "  MaxPooling2D((2, 2)),\n",
    "  Conv2D(64, (3, 3), activation='relu'),\n",
    "  MaxPooling2D((2, 2)),\n",
    "  Conv2D(128, (3, 3), activation=\"relu\"),\n",
    "  MaxPooling2D((2, 2)),\n",
    "  Conv2D(128, (3, 3), activation=\"relu\"),\n",
    "  MaxPooling2D((2, 2)),\n",
    "  Flatten(),\n",
    "  Dense(256, activation=\"relu\"),\n",
    "  Dense(1, activation=\"sigmoid\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 148, 148, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 74, 74, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 72, 72, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 36, 36, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 34, 34, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 17, 17, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 15, 15, 128)       147584    \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 7, 7, 128)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 6272)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               1605888   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,846,977\n",
      "Trainable params: 1,846,977\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "  loss=\"binary_crossentropy\",\n",
    "  optimizer=\"RMSProp\",\n",
    "  metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **1. Reading the Picture Files**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
    "test_datagen = ImageDataGenerator(rescale=1.0/255.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 14000 images belonging to 2 classes.\n",
      "Found 11000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "  train_dir,\n",
    "  target_size=(150, 150),\n",
    "  batch_size=20,\n",
    "  class_mode=\"binary\"\n",
    ")\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "  val_dir,\n",
    "  target_size=(150,150),\n",
    "  batch_size=20,\n",
    "  class_mode=\"binary\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data batch shape: (20, 150, 150, 3)\n",
      "label batch shape: (20,)\n"
     ]
    }
   ],
   "source": [
    "for data_batch, label_batch in train_generator:\n",
    "  print(f\"data batch shape:\", data_batch.shape)\n",
    "  print(f\"label batch shape:\", label_batch.shape)\n",
    "  break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-14 09:23:10.682646: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 56074240 exceeds 10% of free system memory.\n",
      "2022-09-14 09:23:11.667714: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 26542080 exceeds 10% of free system memory.\n",
      "2022-09-14 09:23:12.197721: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 19699200 exceeds 10% of free system memory.\n",
      "2022-09-14 09:23:12.295565: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 23970816 exceeds 10% of free system memory.\n",
      "2022-09-14 09:23:12.386547: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 26542080 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150/150 [==============================] - 149s 973ms/step - loss: 0.7171 - accuracy: 0.5287 - val_loss: 0.6808 - val_accuracy: 0.5323\n",
      "Epoch 2/15\n",
      "150/150 [==============================] - 139s 925ms/step - loss: 0.6754 - accuracy: 0.6050 - val_loss: 0.6165 - val_accuracy: 0.6677\n",
      "Epoch 3/15\n",
      "150/150 [==============================] - 186s 1s/step - loss: 0.6287 - accuracy: 0.6673 - val_loss: 0.5840 - val_accuracy: 0.6873\n",
      "Epoch 4/15\n",
      "150/150 [==============================] - 150s 1s/step - loss: 0.5794 - accuracy: 0.7020 - val_loss: 0.6457 - val_accuracy: 0.6859\n",
      "Epoch 5/15\n",
      "150/150 [==============================] - 142s 948ms/step - loss: 0.5709 - accuracy: 0.7087 - val_loss: 0.5026 - val_accuracy: 0.7536\n",
      "Epoch 6/15\n",
      "150/150 [==============================] - 139s 930ms/step - loss: 0.5398 - accuracy: 0.7267 - val_loss: 0.5413 - val_accuracy: 0.7273\n",
      "Epoch 7/15\n",
      "150/150 [==============================] - 139s 926ms/step - loss: 0.5120 - accuracy: 0.7530 - val_loss: 0.5317 - val_accuracy: 0.7436\n",
      "Epoch 8/15\n",
      "150/150 [==============================] - 165s 1s/step - loss: 0.4902 - accuracy: 0.7690 - val_loss: 0.4788 - val_accuracy: 0.7664\n",
      "Epoch 9/15\n",
      "150/150 [==============================] - 190s 1s/step - loss: 0.4806 - accuracy: 0.7793 - val_loss: 0.5094 - val_accuracy: 0.7568\n",
      "Epoch 10/15\n",
      "150/150 [==============================] - 201s 1s/step - loss: 0.4637 - accuracy: 0.7860 - val_loss: 0.4544 - val_accuracy: 0.8064\n",
      "Epoch 11/15\n",
      "150/150 [==============================] - 232s 2s/step - loss: 0.4495 - accuracy: 0.7960 - val_loss: 0.4464 - val_accuracy: 0.8136\n",
      "Epoch 12/15\n",
      "150/150 [==============================] - 229s 2s/step - loss: 0.4392 - accuracy: 0.7997 - val_loss: 0.4337 - val_accuracy: 0.8014\n",
      "Epoch 13/15\n",
      "150/150 [==============================] - 203s 1s/step - loss: 0.4261 - accuracy: 0.8103 - val_loss: 0.4182 - val_accuracy: 0.8155\n",
      "Epoch 14/15\n",
      "150/150 [==============================] - 165s 1s/step - loss: 0.4194 - accuracy: 0.8190 - val_loss: 0.4474 - val_accuracy: 0.7932\n",
      "Epoch 15/15\n",
      "150/150 [==============================] - 143s 955ms/step - loss: 0.4125 - accuracy: 0.8217 - val_loss: 0.4120 - val_accuracy: 0.8123\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "  train_generator,\n",
    "  steps_per_epoch=150,\n",
    "  epochs=15,\n",
    "  validation_data=validation_generator,\n",
    "  validation_steps=110\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"cats_and_dogs.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8df71d7f3ee6b5c4895fa0a092f36c0c32600308d0bab5cd17897624831d76d3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
